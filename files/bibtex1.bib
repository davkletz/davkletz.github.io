@inproceedings{kletz-etal-2025-polarity,
    title = "Polarity inversion operators in {PLM}",
    author = "Kletz, David  and
      Amsili, Pascal  and
      Candito, Marie",
    editor = "Boleda, Gemma  and
      Roth, Michael",
    booktitle = "Proceedings of the 29th Conference on Computational Natural Language Learning",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.conll-1.20/",
    doi = "10.18653/v1/2025.conll-1.20",
    pages = "312--322",
    ISBN = "979-8-89176-271-8",
    abstract = "From a linguistic perspective, negation is a unique and inherently compositional operator. In this study, we investigate whether the bert-large-cased Pretrained Language Model (PLM) properly encodes this compositional aspect of negation when embedding a token that falls within the scope of negation.To explore this, we train two external Multi-Layer Perceptrons to modify contextual embeddings in a controlled manner. The goal is to reverse the polarity information encoded in the embedding while preserving all other token-related information. The first MLP, called the Negator, transforms a negative polarity into a positive one, while the second, the Affirmator, performs the reverse transformation.We then conduct a series of evaluations to assess the effectiveness of these operators. Our results indicate that while the Negator/Affirmator is functional, it only partially simulates the negation operator. Specifically, applying it recursively does not allow us to recover the original polarity, suggesting an incomplete representation of negation within the PLM{'}s embeddings.In addition, a downstream evaluation on the Negated LAMA dataset reveals that the modifications introduced by the Negator/Affirmator lead to a slight improvement in the model{'}s ability to account for negation in its predictions. However, applying the Negator/Affirmator recursively results in degraded representations, further reinforcing the idea that negation is not fully compositional within PLM embeddings."
}



@inproceedings{lithgow-serrano-etal-2025-assessing,
    title = "Assessing {RAG} System Capabilities on Financial Documents",
    author = "Lithgow-Serrano, Oscar  and
      Kletz, David  and
      Kanjirangat, Vani  and
      Adametz, David  and
      Lunghi, Marzio  and
      Bonesana, Claudio  and
      Tristany-Farinha, Matilde  and
      Li, Yuntao  and
      Repplinger, Detlef  and
      Pierbattista, Marco  and
      Stan, Stefania  and
      Szehr, Oleg",
    editor = "Chen, Chung-Chi  and
      Winata, Genta Indra  and
      Rawls, Stephen  and
      Das, Anirban  and
      Chen, Hsin-Hsi  and
      Takamura, Hiroya",
    booktitle = "Proceedings of The 10th Workshop on Financial Technology and Natural Language Processing",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.finnlp-2.9/",
    doi = "10.18653/v1/2025.finnlp-2.9",
    pages = "124--147"
}


@inproceedings{mitrovic-etal-2025-swushroomsia,
    title = "Swushroomsia at {S}em{E}val-2025 Task 3: Probing {LLM}s' Collective Intelligence for Multilingual Hallucination Detection",
    author = "Mitrovi{\'c}, Sandra  and
      Cornelius, Joseph  and
      Kletz, David  and
      Dolamic, Ljiljana  and
      Rinaldi, Fabio",
    editor = "Rosenthal, Sara  and
      Ros{\'a}, Aiala  and
      Ghosh, Debanjan  and
      Zampieri, Marcos",
    booktitle = "Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.semeval-1.239/",
    pages = "1810--1827",
    ISBN = "979-8-89176-273-2",
    abstract = "This paper introduces a system designed for SemEval-2025 Task 3: Mu-SHROOM, which focuses on detecting hallucinations in multilingual outputs generated by large language models (LLMs). Our approach leverages the collective intelligence of multiple LLMs by prompting several models with three distinct prompts to annotate hallucinations. These individual annotations are then merged to create a comprehensive probabilistic annotation. The proposed system demonstrates strong performance, achieving high accuracy in span detection and strong correlation between predicted probabilities and ground truth annotations."
}



@inproceedings{kletz-etal-2022-methodology,
    title = "A Methodology for Building a Diachronic Dataset of Semantic Shifts and its Application to {QC}-{FR}-Diac-V1.0, a Free Reference for {F}rench",
    author = "Kletz, David  and
      Langlais, Philippe  and
      Lareau, Fran{\c{c}}ois  and
      Drouin, Patrick",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.228/",
    pages = "2117--2125",
    abstract = "Different algorithms have been proposed to detect semantic shifts (changes in a word meaning over time) in a diachronic corpus. Yet, and somehow surprisingly, no reference corpus has been designed so far to evaluate them, leaving researchers to fallback to troublesome evaluation strategies. In this work, we introduce a methodology for the construction of a reference dataset for the evaluation of semantic shift detection, that is, a list of words where we know for sure whether they present a word meaning change over a period of interest. We leverage a state-of-the-art word-sense disambiguation model to associate a date of first appearance to all the senses of a word. Significant changes in sense distributions as well as clear stability are detected and the resulting words are inspected by experts using a dedicated interface before populating a reference dataset. As a proof of concept, we apply this methodology to a corpus of newspapers from Quebec covering the whole 20th century. We manually verified a subset of candidates, leading to QC-FR-Diac-V1.0, a corpus of 151 words allowing one to evaluate the identification of semantic shifts in French between 1910 and 1990."
}



@inproceedings{dehouck-etal-2023-evosem-database,
    title = "{E}vo{S}em: A database of polysemous cognate sets",
    author = "Dehouck, Mathieu  and
      Fran{\c{c}}ois, Alex  and
      Kalyan, Siva  and
      Pastor, Martial  and
      Kletz, David",
    editor = "Tahmasebi, Nina  and
      Montariol, Syrielle  and
      Dubossarsky, Haim  and
      Kutuzov, Andrey  and
      Hengchen, Simon  and
      Alfter, David  and
      Periti, Francesco  and
      Cassotti, Pierluigi",
    booktitle = "Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.lchange-1.7/",
    doi = "10.18653/v1/2023.lchange-1.7",
    pages = "66--75",
    abstract = "Polysemies, or ``colexifications'', are of great interest in cognitive and historical linguistics, since meanings that are frequently expressed by the same lexeme are likely to be conceptually similar, and lie along a common pathway of semantic change. We argue that these types of inferences can be more reliably drawn from polysemies of cognate sets (which we call ``dialexifications'') than from polysemies of lexemes. After giving a precise definition of dialexification, we introduce Evosem, a cross-linguistic database of etymologies scraped from several online sources. Based on this database, we measure for each pair of senses how many cognate sets include them both {---} i.e. how often this pair of senses is ``dialexified''. This allows us to construct a weighted dialexification graph for any set of senses, indicating the conceptual and historical closeness of each pair. We also present an online interface for browsing our database, including graphs and interactive tables. We then discuss potential applications to NLP tasks and to linguistic research."
}



@inproceedings{kletz-etal-2023-self,
    title = "The Self-Contained Negation Test Set",
    author = "Kletz, David  and
      Amsili, Pascal  and
      Candito, Marie",
    editor = "Belinkov, Yonatan  and
      Hao, Sophie  and
      Jumelet, Jaap  and
      Kim, Najoung  and
      McCarthy, Arya  and
      Mohebbi, Hosein",
    booktitle = "Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.blackboxnlp-1.16/",
    doi = "10.18653/v1/2023.blackboxnlp-1.16",
    pages = "212--221",
    abstract = "Several methodologies have recently been proposed to evaluate the ability of Pretrained Language Models (PLMs) to interpret negation. In this article, we build on Gubelmann and Handschuh (2022), which studies the modification of PLMs' predictions as a function of the polarity of inputs, in English. Crucially, this test uses ``self-contained'' inputs ending with a masked position: depending on the polarity of a verb in the input, a particular token is either semantically ruled out or allowed at the masked position. By replicating Gubelmann and Handschuh (2022) experiments, we have uncovered flaws that weaken the conclusions that can be drawn from this test. We thus propose an improved version, the Self-Contained Neg Test, which is more controlled, more systematic, and entirely based on examples forming minimal pairs varying only in the presence or absence of verbal negation in English. When applying our test to the roberta and bert base and large models, we show that only roberta-large shows trends that match the expectations, while bert-base is mostly insensitive to negation. For all the tested models though, in a significant number of test instances the top-1 prediction remains the token that is semantically forbidden by the context, which shows how much room for improvement remains for a proper treatment of the negation phenomenon."
}


@inproceedings{kletz-etal-2023-probing,
    title = "Probing structural constraints of negation in Pretrained Language Models",
    author = "Kletz, David  and
      Candito, Marie  and
      Amsili, Pascal",
    editor = {Alum{\"a}e, Tanel  and
      Fishel, Mark},
    booktitle = "Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)",
    month = may,
    year = "2023",
    address = "T{\'o}rshavn, Faroe Islands",
    publisher = "University of Tartu Library",
    url = "https://aclanthology.org/2023.nodalida-1.54/",
    pages = "541--554",
    abstract = {Contradictory results about the encoding of the semantic impact of negation in pretrained language models (PLMs) have been drawn recently (e.g. Kassner and Sch{\"u}tze (2020); Gubelmann and Handschuh (2022)).In this paper we focus rather on the way PLMs encode negation and its formal impact, through the phenomenon of the Negative Polarity Item (NPI) licensing in English.More precisely, we use probes to identify which contextual representations best encode 1) the presence of negation in a sentence, and 2) the polarity of a neighboring masked polarity item. We find that contextual representations of tokens inside the negation scope do allow for (i) a better prediction of the presence of ``not'' compared to those outside the scope and (ii) a better prediction of the right polarity of a masked polarity item licensed by ``not'', although the magnitude of the difference varies from PLM to PLM. Importantly, in both cases the trend holds even when controlling for distance to ``not''.This tends to indicate that the embeddings of these models do reflect the notion of negation scope, and do encode the impact of negation on NPI licensing. Yet, further control experiments reveal that the presence of other lexical items is also better captured when using the contextual representation of a token within the same syntactic clause than outside from it, suggesting that PLMs simply capture the more general notion of syntactic clause.}
}


